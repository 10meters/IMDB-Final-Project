{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba79425b-6ce3-44ae-a597-37861eca2bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T07:34:33.693122Z",
     "iopub.status.busy": "2025-04-26T07:34:33.691456Z",
     "iopub.status.idle": "2025-04-26T07:34:36.568245Z",
     "shell.execute_reply": "2025-04-26T07:34:36.565827Z",
     "shell.execute_reply.started": "2025-04-26T07:34:33.693048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kneed\n",
      "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /opt/conda/lib/python3.12/site-packages (from kneed) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from kneed) (1.14.1)\n",
      "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: kneed\n",
      "Successfully installed kneed-0.8.5\n",
      "Successfully Imported\n"
     ]
    }
   ],
   "source": [
    "!pip install kneed\n",
    "print('Successfully Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95c923e3-989f-48b9-a40b-631598f9cecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T04:16:09.921513Z",
     "iopub.status.busy": "2025-04-26T04:16:09.920910Z",
     "iopub.status.idle": "2025-04-26T04:16:10.627754Z",
     "shell.execute_reply": "2025-04-26T04:16:10.626502Z",
     "shell.execute_reply.started": "2025-04-26T04:16:09.921464Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kneed import KneeLocator\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223b4560-9b42-4531-9dcc-8bdcb2d4d17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T07:16:54.838432Z",
     "iopub.status.busy": "2025-04-26T07:16:54.837773Z",
     "iopub.status.idle": "2025-04-26T07:16:54.850626Z",
     "shell.execute_reply": "2025-04-26T07:16:54.849236Z",
     "shell.execute_reply.started": "2025-04-26T07:16:54.838375Z"
    }
   },
   "outputs": [],
   "source": [
    "#Made with ChatGPT\n",
    "def plot_two_countplots(\n",
    "    df1,\n",
    "    df2,\n",
    "    col=\"Rating\",\n",
    "    labels=(\"Test Classes\", \"Nontest Classes\"),\n",
    "    figsize=(12, 5)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots side-by-side countplots of `col` for df1 and df2.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2 : pandas.DataFrame\n",
    "        The two dataframes to plot.\n",
    "    col : str, default \"mycol\"\n",
    "        Name of the column (with two possible values) to count.\n",
    "    labels : tuple of str, default (\"DataFrame 1\", \"DataFrame 2\")\n",
    "        Titles to use for the left and right plots.\n",
    "    figsize : tuple, default (12, 5)\n",
    "        Size of the overall figure (width, height).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # Left plot\n",
    "    sns.countplot(x=col, data=df1, ax=axes[0])\n",
    "    axes[0].set_title(labels[0])\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "    # Right plot\n",
    "    sns.countplot(x=col, data=df2, ax=axes[1])\n",
    "    axes[1].set_title(labels[1])\n",
    "    axes[1].set_xlabel(col)\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9294ab87-b446-46ad-adf3-4b8550d12ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T07:53:22.219748Z",
     "iopub.status.busy": "2025-04-26T07:53:22.219056Z",
     "iopub.status.idle": "2025-04-26T07:53:22.238803Z",
     "shell.execute_reply": "2025-04-26T07:53:22.237651Z",
     "shell.execute_reply.started": "2025-04-26T07:53:22.219686Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scree(evr_source, title=\"Scree Plot\", figsize=(8, 5)):\n",
    "    \"\"\"\n",
    "    Plot a scree plot with cumulative variance and automatic elbow detection using kneed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    evr_source : array-like or sklearn.decomposition.PCA\n",
    "        - If PCA: uses its .explained_variance_ratio_.\n",
    "        - If 1D array-like: treated as the explained_variance_ratio_ directly.\n",
    "        - If 2D array-like: treated as PC scores (n_samples x n_components),\n",
    "          and explained_variance_ratio_ is computed as var(scores, axis=0) / sum(var).\n",
    "    title : str\n",
    "        Plot title.\n",
    "    figsize : tuple\n",
    "        Figure size (inches).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    elbow_pc : int\n",
    "        1-based index of the detected elbow component.\n",
    "    elbow_cum_var : float\n",
    "        Cumulative explained-variance ratio at that elbow.\n",
    "    \"\"\"\n",
    "    # 1) Extract or compute explained_variance_ratio_\n",
    "    if isinstance(evr_source, PCA):\n",
    "        evr = np.array(evr_source.explained_variance_ratio_)\n",
    "    else:\n",
    "        arr = np.asarray(evr_source)\n",
    "        if arr.ndim == 1:\n",
    "            evr = arr\n",
    "        elif arr.ndim == 2:\n",
    "            var = np.var(arr, axis=0, ddof=0)\n",
    "            evr = var / np.sum(var)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"evr_source must be PCA, 1D explained-variance array, or 2D PC-scores array\"\n",
    "            )\n",
    "\n",
    "    n = len(evr)\n",
    "    x = np.arange(1, n + 1)\n",
    "\n",
    "    # 2) Elbow detection using kneed\n",
    "    kneedle = KneeLocator(x, evr, curve=\"convex\", direction=\"decreasing\")\n",
    "    elbow_idx = kneedle.knee\n",
    "    if elbow_idx is None:\n",
    "        raise RuntimeError(\"KneeLocator failed to detect an elbow\")\n",
    "\n",
    "    # 3) Compute cumulative variance\n",
    "    cum_evr = np.cumsum(evr)\n",
    "    elbow_cum_var = cum_evr[int(elbow_idx) - 1]\n",
    "\n",
    "    # 4) Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(x, evr, marker='o', linestyle='-', label=\"Explained Variance\")\n",
    "    ax.plot(x, cum_evr, marker='s', linestyle='--', label=\"Cumulative Variance\")\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True, nbins=20))\n",
    "    ax.set_xlabel(\"Principal Component\")\n",
    "    ax.set_ylabel(\"Variance Ratio\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "    # 5) Annotate elbow cumulative variance with offset to avoid overlap\n",
    "    offset = (0, 20) if elbow_cum_var < 0.5 else (0, -40)\n",
    "    ax.annotate(\n",
    "        f\"Elbow: PC {elbow_idx}\\n{elbow_cum_var:.2%} cumulative\",\n",
    "        xy=(elbow_idx, elbow_cum_var),\n",
    "        xytext=offset,\n",
    "        textcoords='offset points',\n",
    "        ha='center',\n",
    "        va='bottom' if offset[1] > 0 else 'top',\n",
    "        arrowprops=dict(arrowstyle='->', lw=1)\n",
    "    )\n",
    "\n",
    "    # 6) Final touches\n",
    "    ax.legend(loc='best')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return elbow_idx, elbow_cum_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7087c1-6762-4d0a-a380-f0b735d5b356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T04:17:14.278025Z",
     "iopub.status.busy": "2025-04-27T04:17:14.277326Z",
     "iopub.status.idle": "2025-04-27T04:17:15.073995Z",
     "shell.execute_reply": "2025-04-27T04:17:15.072538Z",
     "shell.execute_reply.started": "2025-04-27T04:17:14.277965Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def biplot(orig, pcs, feature_names=None, pc_indices=(0, 1), top_arrows=10,\n",
    "           arrow_scale=None, figsize=(8, 6), title=None, predictions=None):\n",
    "    \"\"\"\n",
    "    Create a PCA biplot showing samples in PC space and arrows for original features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    orig : array-like or DataFrame, shape (n_samples, n_features)\n",
    "        The original features (e.g., token counts or standardized variables).\n",
    "    pcs : array-like or DataFrame, shape (n_samples, n_components)\n",
    "        The principal component scores for each sample.\n",
    "    feature_names : list of str, length n_features, optional\n",
    "        Names of the original features. If None and orig is a DataFrame, uses orig.columns.\n",
    "    pc_indices : tuple(int, int), default (0, 1)\n",
    "        Indices of the two principal components to plot (0-based).\n",
    "    top_arrows : int, default 10\n",
    "        Number of features (arrows) to display by descending loading magnitude.\n",
    "    arrow_scale : float or None, default None\n",
    "        Scaling factor for loadings arrows. If None, computed automatically.\n",
    "    figsize : tuple, default (8, 6)\n",
    "        Figure size.\n",
    "    title : str, optional\n",
    "        Title of the plot.\n",
    "    predictions : array-like, shape (n_samples,), optional\n",
    "        Class labels or continuous values for coloring points.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax : matplotlib Figure and Axes\n",
    "        The figure and axes objects containing the biplot.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    X = orig.values if hasattr(orig, 'values') else np.asarray(orig)\n",
    "    Z = pcs.values if hasattr(pcs, 'values') else np.asarray(pcs)\n",
    "\n",
    "    # Select PCs\n",
    "    pc_x, pc_y = pc_indices\n",
    "    scores = Z[:, [pc_x, pc_y]]\n",
    "\n",
    "    # Feature names\n",
    "    if feature_names is None:\n",
    "        if hasattr(orig, 'columns'):\n",
    "            feature_names = list(orig.columns)\n",
    "        else:\n",
    "            feature_names = [f\"Var{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "    # Center original features\n",
    "    Xc = X - np.mean(X, axis=0)\n",
    "\n",
    "    # Compute loadings: covariance between features and PC scores\n",
    "    loadings = (Xc.T @ scores) / (Xc.shape[0] - 1)\n",
    "\n",
    "    # Compute magnitude of loadings for the two PCs\n",
    "    magnitude = np.sqrt(loadings[:, 0]**2 + loadings[:, 1]**2)\n",
    "\n",
    "    # Select top features by magnitude\n",
    "    top_idx = np.argsort(magnitude)[-top_arrows:]\n",
    "\n",
    "    # Auto-scale arrows\n",
    "    if arrow_scale is None:\n",
    "        range_scores = np.max(scores, axis=0) - np.min(scores, axis=0)\n",
    "        scale_factor = 0.8 * np.max(range_scores) / np.max(magnitude)\n",
    "    else:\n",
    "        scale_factor = arrow_scale\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot points with seaborn for hue support\n",
    "    if predictions is not None:\n",
    "        sns.scatterplot(x=scores[:, 0], y=scores[:, 1], hue=predictions,\n",
    "                        palette='deep', ax=ax, alpha=0.7, legend='full')\n",
    "    else:\n",
    "        ax.scatter(scores[:, 0], scores[:, 1], alpha=0.7)\n",
    "\n",
    "    # Draw arrows for top features\n",
    "    for i in top_idx:\n",
    "        ax.arrow(0, 0,\n",
    "                 loadings[i, 0] * scale_factor,\n",
    "                 loadings[i, 1] * scale_factor,\n",
    "                 head_width=0.02 * np.max(range_scores),\n",
    "                 head_length=0.02 * np.max(range_scores),\n",
    "                 length_includes_head=True, color='r')\n",
    "        ax.text(loadings[i, 0] * scale_factor * 1.05,\n",
    "                loadings[i, 1] * scale_factor * 1.05,\n",
    "                feature_names[i], color='r', ha='center', va='center')\n",
    "\n",
    "    ax.set_xlabel(f\"PC{pc_x + 1}\")\n",
    "    ax.set_ylabel(f\"PC{pc_y + 1}\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.axhline(0, color='grey', linewidth=0.8)\n",
    "    ax.axvline(0, color='grey', linewidth=0.8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec7428-77cc-45f4-83c0-c54a3a8ab656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T04:38:40.208553Z",
     "iopub.status.busy": "2025-04-27T04:38:40.207875Z",
     "iopub.status.idle": "2025-04-27T04:38:40.229623Z",
     "shell.execute_reply": "2025-04-27T04:38:40.228159Z",
     "shell.execute_reply.started": "2025-04-27T04:38:40.208494Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "\n",
    "def wordcloud_pc(orig, pcs, feature_names=None, pc_index=0,\n",
    "                 max_words=100, width=800, height=400,\n",
    "                 scale=1, colormap_positive='Reds', colormap_negative='Blues',\n",
    "                 background_color='white', title=None):\n",
    "    \"\"\"\n",
    "    Generate and display a wordcloud for a specified principal component.\n",
    "\n",
    "    Word sizes are proportional to the magnitude of each feature's loading on the PC,\n",
    "    and colors indicate the loading direction (sign).\n",
    "    \"\"\"\n",
    "    # Convert to numpy\n",
    "    X = orig.values if hasattr(orig, 'values') else np.asarray(orig)\n",
    "    Z = pcs.values if hasattr(pcs, 'values') else np.asarray(pcs)\n",
    "\n",
    "    # Features\n",
    "    if feature_names is None:\n",
    "        if hasattr(orig, 'columns'):\n",
    "            feature_names = list(orig.columns)\n",
    "        else:\n",
    "            feature_names = [f\"Var{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "    # Center original data\n",
    "    Xc = X - np.mean(X, axis=0)\n",
    "\n",
    "    # Compute loadings for the component\n",
    "    scores_pc = Z[:, pc_index]\n",
    "    loadings = (Xc.T @ scores_pc) / (Xc.shape[0] - 1)\n",
    "\n",
    "    # Build frequency dictionary: magnitude -> word size\n",
    "    freq = {feature_names[i]: abs(loadings[i]) for i in range(len(loadings))}\n",
    "    # Limit to top N\n",
    "    top = dict(sorted(freq.items(), key=lambda x: x[1], reverse=True)[:max_words])\n",
    "\n",
    "    # Color function based on sign, returning hex strings\n",
    "    min_mag = np.min(np.abs(loadings))\n",
    "    max_mag = np.max(np.abs(loadings))\n",
    "    \n",
    "    def color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "        \n",
    "        val = loadings[feature_names.index(word)]\n",
    "        return 'darkred' if val <= 0 else 'darkgreen'\n",
    "\n",
    "\n",
    "    wc = WordCloud(width=width, height=height, scale=scale,\n",
    "                   background_color=background_color,\n",
    "                   prefer_horizontal=1.0,\n",
    "                   color_func=color_func)\n",
    "    wc.generate_from_frequencies(top)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(width/100, height/100))\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return wc, fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f681a5c-047f-4d1f-99cc-7df9b786bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pc_loadings_final(orig, pcs, feature_names=None, pc_index=0,\n",
    "                          top_n=20, horizontal=True,\n",
    "                          pos_color='#2ca02c', neg_color='#d62728',\n",
    "                          title=None, figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Final bulletproof version:\n",
    "    - One solid color per bar\n",
    "    - Length = absolute loading magnitude\n",
    "    - Clear value annotations\n",
    "    \"\"\"\n",
    "    # Convert to arrays\n",
    "    X = np.asarray(orig)\n",
    "    Z = np.asarray(pcs)\n",
    "    \n",
    "    # Get feature names\n",
    "    if feature_names is None:\n",
    "        if hasattr(orig, 'columns'):\n",
    "            feature_names = orig.columns.tolist()\n",
    "        else:\n",
    "            feature_names = [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "    # Compute loadings (covariance method)\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    loadings = (X_centered.T @ Z[:, pc_index]) / (X.shape[0] - 1)\n",
    "\n",
    "    # Sort features by absolute loading magnitude\n",
    "    sorted_indices = np.argsort(np.abs(loadings))[::-1][:top_n]\n",
    "    sorted_names = [feature_names[i] for i in sorted_indices]\n",
    "    sorted_loadings = loadings[sorted_indices]\n",
    "    abs_loadings = np.abs(sorted_loadings)\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot horizontal bars\n",
    "    if horizontal:\n",
    "        y_pos = np.arange(len(sorted_names))\n",
    "        colors = [pos_color if val >= 0 else neg_color for val in sorted_loadings]\n",
    "\n",
    "        # Plot bars\n",
    "        bars = ax.barh(y_pos, abs_loadings, color=colors, height=0.8)\n",
    "\n",
    "        # Annotate values\n",
    "        for i, (val, abs_val) in enumerate(zip(sorted_loadings, abs_loadings)):\n",
    "            ax.text(abs_val, i, f\" {val:.3f}\", \n",
    "                    va='center', ha='left', fontsize=9)\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(sorted_names)\n",
    "        ax.invert_yaxis()  # Highest magnitude at top\n",
    "        ax.set_xlabel(\"Loading Magnitude (Absolute Value)\")\n",
    "        ax.set_title(title or f\"PC{pc_index+1} Loadings (Top {top_n})\")\n",
    "\n",
    "    # Plot vertical bars\n",
    "    else:\n",
    "        x_pos = np.arange(len(sorted_names))\n",
    "        colors = [pos_color if val >= 0 else neg_color for val in sorted_loadings]\n",
    "\n",
    "        # Plot bars\n",
    "        bars = ax.bar(x_pos, abs_loadings, color=colors, width=0.8)\n",
    "\n",
    "        # Annotate values\n",
    "        for i, (val, abs_val) in enumerate(zip(sorted_loadings, abs_loadings)):\n",
    "            ax.text(i, abs_val, f\"{val:.3f}\", \n",
    "                    ha='center', va='bottom', fontsize=9, rotation=90)\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(sorted_names, rotation=90)\n",
    "        ax.set_ylabel(\"Loading Magnitude (Absolute Value)\")\n",
    "        ax.set_title(title or f\"PC{pc_index+1} Loadings (Top {top_n})\")\n",
    "\n",
    "    # Legend\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=pos_color, label=\"Positive Loading\"),\n",
    "        Patch(facecolor=neg_color, label=\"Negative Loading\")\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
